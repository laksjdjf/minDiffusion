{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a8ecd8c-a114-4cf9-bd29-618df47a244c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T06:44:33.956985Z",
     "iopub.status.busy": "2023-02-06T06:44:33.956296Z",
     "iopub.status.idle": "2023-02-06T06:44:34.854047Z",
     "shell.execute_reply": "2023-02-06T06:44:34.853302Z",
     "shell.execute_reply.started": "2023-02-06T06:44:33.956895Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "class AnimeDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        files = os.listdir(path)\n",
    "        self.file_list = [os.path.join(path,file) for file in files]\n",
    "        self.transform = transforms.Compose(\n",
    "        [\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "         ]\n",
    "    )\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.file_list[i])\n",
    "        return self.transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce74bfd-16ad-4dd6-b643-ee8ba40de19a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T06:55:31.758624Z",
     "iopub.status.busy": "2023-02-06T06:55:31.758062Z",
     "iopub.status.idle": "2023-02-06T06:55:31.765720Z",
     "shell.execute_reply": "2023-02-06T06:55:31.765160Z",
     "shell.execute_reply.started": "2023-02-06T06:55:31.758599Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from mindiffusion.vae import VAE\n",
    "\n",
    "def train_anime(\n",
    "    n_epoch: int = 100, device: str = \"cuda:0\", load_pth: Optional[str] = None\n",
    ") -> None:\n",
    "\n",
    "    ###設定############\n",
    "    n_feat = 64\n",
    "    batch_size = 256\n",
    "    downs = 3\n",
    "    lr = 1e-4\n",
    "    dataset_dir = \"/storage/animeface/images/\"\n",
    "    resume = \"vae1.pth\"\n",
    "    ###################\n",
    "\n",
    "    vae = VAE(3,n_feat,downs)\n",
    "\n",
    "    vae.to(device)\n",
    "    \n",
    "    if resume is not None:\n",
    "        vae.load_state_dict(torch.load(resume))\n",
    "    dataset = AnimeDataset(dataset_dir)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    optim = torch.optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        print(f\"Epoch {i} : \")\n",
    "        vae.train()\n",
    "\n",
    "        pbar = tqdm(dataloader)\n",
    "        loss_ema = None\n",
    "        for x in pbar:\n",
    "            optim.zero_grad()\n",
    "            x = x.to(device)\n",
    "            x_pred, mu, log_var, _ = vae(x)\n",
    "            loss, _, _ = vae.loss_function(x,x_pred,mu,log_var)\n",
    "            loss.backward()\n",
    "            if loss_ema is None:\n",
    "                loss_ema = loss.item()\n",
    "            else:\n",
    "                loss_ema = 0.9 * loss_ema + 0.1 * loss.item()\n",
    "            pbar.set_description(f\"loss: {loss_ema:.4f}\")\n",
    "            optim.step()\n",
    "\n",
    "        vae.eval()\n",
    "        with torch.no_grad():\n",
    "            xh, _, _ , _ = vae(x[:8])\n",
    "            xset = torch.cat([xh, x[:8]], dim=0)\n",
    "            grid = make_grid(xset, normalize=True, value_range=(-1, 1), nrow=4)\n",
    "            save_image(grid, f\"./contents/vae{str(i).zfill(3)}.png\")\n",
    "\n",
    "            # save model\n",
    "            torch.save(vae.state_dict(), f\"./vae{i%3}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d383e50-e61b-4870-9487-84c95ea4c764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T06:55:32.404266Z",
     "iopub.status.busy": "2023-02-06T06:55:32.403697Z",
     "iopub.status.idle": "2023-02-06T07:25:12.064875Z",
     "shell.execute_reply": "2023-02-06T07:25:12.063520Z",
     "shell.execute_reply.started": "2023-02-06T06:55:32.404237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -1.3733: 100%|██████████| 249/249 [03:37<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -2.7952: 100%|██████████| 249/249 [03:37<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -3.2604: 100%|██████████| 249/249 [03:38<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -3.7352: 100%|██████████| 249/249 [03:37<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -3.8830: 100%|██████████| 249/249 [03:38<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -4.1223: 100%|██████████| 249/249 [03:38<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -4.1879: 100%|██████████| 249/249 [03:38<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -4.1972: 100%|██████████| 249/249 [03:38<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -4.2617:  11%|█         | 27/249 [00:25<03:27,  1.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_anime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mtrain_anime\u001b[0;34m(n_epoch, device, load_pth)\u001b[0m\n\u001b[1;32m     45\u001b[0m     loss_ema \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     loss_ema \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m \u001b[38;5;241m*\u001b[39m loss_ema \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_ema\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_anime(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262851a3-b9eb-403c-857a-eaaa88fbf7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
